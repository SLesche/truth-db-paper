# Discussion
In this paper, we introduce the Truth Effect Database (TED), a large-scale, open-access repository of trial-level data on truth judgments. TED is designed to support cumulative, reproducible research on the illusory truth effect (ITE) by standardizing and centralizing data from a wide range of studies. It currently aggregates data from 59 studies in 29 publications, spanning 12,242 participants and 808,231 trials, accounting for a wide range of dispositional and contextual variables – including experimental instructions, task during initial exposure, number of repetitions, and length of the retention interval. With its growing size, TED provides a critical resource for investigating how repetition shapes belief formation – a process of increasing relevance in the digital age, where repeated exposure to false or misleading information is pervasive.

Our goal in developing TED was to address key challenges in open research data: the fragmentation of data across studies, the lack of standard formats for sharing experimental data, and the resulting lack of interoperability and reusability (Crüwell et al., 2023; Hardwicke et al., 2021). To meet these challenges, we provide a structured SQL-based schema that organizes data at multiple levels – including publications, experiments, participants, and individual trials. This structure allows for fine-grained analysis while maintaining consistency across diverse datasets.

We also provide tools to facilitate access and use of the database. In particular, the R package acdcquery (Lesche, 2025) allows users to extract data from TED with flexible filtering criteria, supporting both simple and complex queries. Additionally, we have developed a web-based data entry interface that automatically checks for consistency and flags incorrect variable names or entries (https://slesche.github.io/truth-effect-database/). This helps maintain high standards for incoming data and ensures that TED remains a reliable resource for the community, while simplifying the submission process and lowering the barrier to entry.

To illustrate the analytical potential of TED, we fitted multilevel models predicting truth judgments. By estimating random effects at the statement, subject, and experiment levels, we investigated where variance in the truth effect originates. 

In both the Likert-scale and dichotomous truth judgment data, we found that the random slopes of repetition on the statement level showed very little variance. This suggests that specific properties of individual statements (e.g., their semantic content or plausibility) have limited influence on the magnitude of the truth effect. However, statement-level variance in random intercepts was relatively large. This is consistent with expectations: some statements are objectively easier to judge as true or false, while others are more ambiguous, leading to baseline differences in overall truth ratings.

We also observed substantial variance in the experiment-level random effect of repetition. This is unsurprising, as experiments varied considerably in design features such as the number of statements, delay between exposure and judgment phase, or whether participants were warned about repetition. Nevertheless, the experiment-level variance in the effect of repetition was still smaller than at the subject level.

In fact, the largest variance in the truth effect emerged at the subject level, indicating substantial individual differences in susceptibility to the repetition effect. This finding aligns with growing interest in understanding the psychological traits or cognitive mechanisms that moderate the truth effect at the individual level. However, efforts to study individual differences in the truth effect have so far produced mixed results (for an overview, see the introduction). 

In this exemplary use of TED, we furthermore explored whether the individual variance in the ITE is moderated by the delay between exposure and judgment phase – a key design feature in truth effect experiments. TED allowed us to perform an analysis using a large number of ITE data sets, estimating individual variability in the truth effect when the exposure and judgment occur on the same day, as opposed to a delay of at least one day, while additionally taking variance at the experiment and statement level into account. The results revealed that the variance in the repetition effect at the subject level was larger when truth judgments for repeated (vs. new) statements were made on the same day as the exposure phase, compared to when the judgment phases were postponed to a later date (i.e., at least one day later). Based on the posterior distributions, we compared these random effects between conditions (retention interval < 1 day vs. retention interval >= 1 day). Results demonstrated that this difference is different from 0, indicating credible differences in the subject-level variability in the illusory truth effect as a function of the delay between exposure and judgment phase. On a theoretical level, these differences as a function of retention interval length may reflect variations in memory strength. After a relatively short delay, memory traces are likely still robust, making it easier for individuals to identify the earlier presentation as the source of the familiarity experience. On a theoretical level, these differences as a function of retention interval length may reflect variations in memory strength. Arkes et al. (1989) found that the illusory truth effect increases when repeated statements are attributed to sources external to the experiment. We argue that after a relatively short delay, memory traces are likely still robust, making it easier for individuals to identify the earlier presentation as the source of the familiarity experience. Consequently, as long as the feeling of fluency can be traced back to repetition within the experimental context, certain dispositional factors may reduce the likelihood of relying on repetition-based fluency (e.g., a higher preference for deliberation, a lower need for cognitive closure). After longer intervals (e.g., one week), the source of familiarity likely becomes less distinct, reducing the interaction between repetition and dispositional factors. Once the familiarity can no longer be attributed to the experimental context, reliance on repetition-induced fluency may serve as a valid cue for truth evaluation under uncertainty (Reber & Unkelbach, 2010). This idea aligns well with prior research demonstrating that dispositional effects (e.g., Need for Cognitive Closure) tend to emerge after relatively short retention intervals (e.g., 10 minutes) rather than longer ones (e.g., one week; Stump et al., 2022).  

Finally, although our findings align well with previous research, we emphasize that these preliminary results and theoretical assumptions should be interpreted with caution, as we did not control for potential confounding factors such as sample composition, procedural variation, or other study-level covariates. Overall, these initial analyses were primarily intended to demonstrate the usefulness of TED for addressing complex research questions that would be difficult to examine using data from a single study. The open and extensible nature of TED ensures that these questions can be revisited and refined as the database continues to grow. We see this as a first step toward more nuanced investigations of the truth effect grounded in large-scale, reproducible data.

## Limitations
Different limitations of the current version of TED should be acknowledged. First, TED is not a comprehensive repository of all truth effect studies. The dataset is based primarily on the systematic review by Henderson et al. (2022), and we have updated the database through our own literature searches. Consequently, any inferences drawn from analyses of TED should be interpreted in light of this selection bias: TED includes only those studies that have already made their data publicly available. To fully resolve issues of selection and interoperability, all original data would need to be made publicly accessible and well-documented. Nevertheless, TED represents a step toward this goal and is uniquely positioned to facilitate data harmonization; the entry mask and harmonization efforts implemented in the database reduce barriers to interoperable data for future research.

Second, the submission process still requires contributors to send data directly to the maintainers via email. Although this procedure is relatively low-tech, it was deliberately designed to minimize points of failure and attack, avoid server hosting costs, and foster direct contact between contributors and maintainers, which can support follow-up and clarification. Similarly, TED currently does not provide API or server access. Instead, data are accessible via a downloadable file or directly through the accompanying R package, allowing researchers to interact with the database at their own pace and modify it as needed while limiting project complexity and costs.

Third, the database is not static. Information may change over time as new studies are added, errors are corrected, or classifications are refined. In particular, the veracity of statements encoded in the database reflects their status at the time of the publication in which they were used. Because factual accuracy can change over time, researchers should exercise caution when using statement texts directly from TED and consider re-evaluating statement accuracy where necessary. 

Expansion of the database is also constrained by available resources. In the absence of dedicated institutional support or direct funding, growth depends on voluntary submissions from researchers and on targeted survey efforts conducted by the maintenance team. We have aimed to make contribution to TED as straightforward as possible to lower barriers to participation and aim to survey new research to add to TED periodically to reach out to potential contributors directly. All contributions help improve the FAIRness of illusory truth effect data and also increase the visibility of contributors’ work. We are also hopeful that broader initiatives promoting the development and use of large-scale databases, such as the recent call for submissions using large-scale data in Psychometrika (Psychometric Society, 2026), will further strengthen community support for TED.

Finally, because TED evolves over time, researchers should ensure that the version of the database they use matches the most current release. To facilitate this, the accompanying R package provides the check_ted() function, which allows users to compare a locally stored SQLite file with the latest version available online. If discrepancies are detected, users can update their local copy using update_ted() or download a specific release via download_ted(path, tag = "v1.1.0-example"), thereby ensuring transparency and reproducibility in analyses based on TED.


## Future research
TED offers a unique foundation for advancing research through open, cumulative, and reproducible science. As the database grows in scope and depth, we anticipate several promising directions for future research and methodological development that TED is particularly well-positioned to support.

One immediate application lies in enabling living meta-analyses of truth effect data that can evolve as new studies are contributed. Importantly, the present data does not represent a random or comprehensive sample of all published ITE studies and therefore does not support a formal meta-analysis. Nevertheless, TED can be used to estimate average effect sizes among studies with openly available data. Given these limitations, we chose not to report an aggregate effect size in the current paper. However, we provide a proof-of-concept meta-analysis on TED’s website (https://slesche.github.io/ted-site/explore.html#meta-analysis). 

Closely related, TED can support customized power analyses based on empirical variance from real experimental data. Researchers designing new studies can use TED’s trial-level data to simulate expected effects based on previously collected data with similar study characteristics, improving the precision and efficiency of future study planning.

TED’s reproducibility potential lies in its ability to support both the replication and reanalysis of existing studies using openly available, trial-level data. Researchers can directly replicate earlier truth effect experiments by matching procedural details drawn from the database, or they can reanalyze existing datasets to test new hypotheses, apply alternative statistical models, or verify published results. Thus, TED facilitates both direct and conceptual replications and provides a foundation for transparent, data-driven reassessment of prior findings.

Beyond supporting replications, TED offers a foundation for formal modeling approaches to the truth effect. Its detailed trial-level data and metadata allow researchers to fit and validate cognitive process models – such as drift diffusion (see e.g., Ratcliff & McKoon, 2008) or multinomial processing tree models (see e.g., Calio et al., 2020; Unkelbach & Stahl, 2009). 

Importantly, these efforts are supported by TED’s intentional focus on long-term sustainability. The database is built with minimal reliance on proprietary infrastructure or paid software. All tools and data are hosted on open platforms, primarily GitHub, and contributions are made through transparent, version-controlled workflows. This lightweight architecture was chosen to promote longevity and ensure that TED remains accessible and modifiable regardless of funding cycles or institutional changes.

To ensure proper attribution and foster community investment, users of TED data are expected to cite all original publications corresponding to the datasets they use. In return, contributions to TED not only extend the utility of existing research but also amplify the visibility of individual studies, creating a mutually reinforcing incentive structure for both data sharing and reuse.

As TED continues to grow, we encourage researchers not only to contribute data but also to build on TED’s infrastructure itself. TED itself is an extension of the Attentional Control Data Collection (ACDC) project (Haaf et al., 2025), improving on data submission and ease-of-use. Both projects can serve as a jumping-off point for future database development. All aspects of our project, including the SQL schema, submission interface, R extraction package, and the interactive overview website, are open source and fully forkable. Researchers are invited to reuse or adapt these components to develop similar infrastructures for other domains of psychological or behavioral science. In doing so, TED can help establish a broader culture of open, scalable, and sustainable data practices in experimental research.

Taken together, these features position TED as a blueprint for cumulative science: one that supports rigorous replication, sophisticated cognitive modeling, empirical synthesis, and infrastructure reusability while lowering the barriers to collaboration and long-term research development.

## Conclusion
In this paper, we introduced the Truth Effect Database (TED), a structured, large-scale resource for cumulative research on truth judgments. TED includes not only standardized, trial-level data but also open tools for user interaction, including a submission interface and an R package for flexible data extraction. Additional details can be found on TED’s homepage (https://slesche.github.io/ted-site/).

We illustrated the utility of TED through Bayesian multilevel analyses, which highlighted substantial variance in the illusory truth effect at the subject level and provided new evidence that individual differences in susceptibility to the truth effect systematically vary as a function of the retention interval length. These findings point to the need for further theoretical and empirical work on individual differences in susceptibility to information repetition.

Beyond this first demonstration, TED provides the foundation for a wide range of future research. These include (living) meta-analyses, simulation-based power analyses, rigorous replication and reanalysis of existing studies, and the development of formal cognitive models. As an open and extensible infrastructure, TED also serves as a blueprint for sustainable, community-driven database development in psychological science.

